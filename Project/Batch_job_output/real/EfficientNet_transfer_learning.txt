real
EfficientNet_transfer_learning
Job started
Fri Nov 26 13:55:20 MST 2021
=========================================================================
Necessary env loaded
Going to train model on  real




**************************************************
**************************************************
**************************************************************************************************** Going to print if GPU is used
**************************************************************************************************** Num GPUs Available: 1
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Total 10170 images found in directory /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/train/
Total 1388 images found in directory /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/validation/
Total 1285 images found in directory /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/test/
Over
Base /home/mdabdullahal.alamin/alamin/face_mask
 Data dir: /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/
Train dir: /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/train/
 Validation dir: /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/validation/
 Test dir: /home/mdabdullahal.alamin/alamin/face_mask/dataset/RMFD/organized/test/
Found 10170 images belonging to 2 classes.
Found 1388 images belonging to 2 classes.
Found 1285 images belonging to 2 classes.
**************************************************************************************************** ===> Model name: EfficientNet_transfer_learning



 =====================================> Current Model output dir: /home/mdabdullahal.alamin/alamin/face_mask/model_output/real/batch_jobs/EfficientNet_transfer_learning   ===============================
Going to REMOVE and CREATE directory: /home/mdabdullahal.alamin/alamin/face_mask/model_output/real/batch_jobs/EfficientNet_transfer_learning
Creating directory /home/mdabdullahal.alamin/alamin/face_mask/model_output/real/batch_jobs/EfficientNet_transfer_learning.
Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5
     8192/258076736 [..............................] - ETA: 2s    40960/258076736 [..............................] - ETA: 5:46   114688/258076736 [..............................] - ETA: 3:58   303104/258076736 [..............................] - ETA: 2:13   770048/258076736 [..............................] - ETA: 1:09  1966080/258076736 [..............................] - ETA: 33s   5046272/258076736 [..............................] - ETA: 15s  9420800/258076736 [>.............................] - ETA: 9s  13418496/258076736 [>.............................] - ETA: 7s 17596416/258076736 [=>............................] - ETA: 6s 21757952/258076736 [=>............................] - ETA: 5s 25935872/258076736 [==>...........................] - ETA: 4s 30130176/258076736 [==>...........................] - ETA: 4s 34316288/258076736 [==>...........................] - ETA: 4s 38502400/258076736 [===>..........................] - ETA: 4s 42713088/258076736 [===>..........................] - ETA: 3s 46907392/258076736 [====>.........................] - ETA: 3s 51093504/258076736 [====>.........................] - ETA: 3s 55320576/258076736 [=====>........................] - ETA: 3s 59514880/258076736 [=====>........................] - ETA: 3s 63709184/258076736 [======>.......................] - ETA: 3s 67919872/258076736 [======>.......................] - ETA: 2s 72097792/258076736 [=======>......................] - ETA: 2s 76292096/258076736 [=======>......................] - ETA: 2s 80519168/258076736 [========>.....................] - ETA: 2s 84697088/258076736 [========>.....................] - ETA: 2s 88875008/258076736 [=========>....................] - ETA: 2s 93036544/258076736 [=========>....................] - ETA: 2s 97263616/258076736 [==========>...................] - ETA: 2s101507072/258076736 [==========>...................] - ETA: 2s105717760/258076736 [===========>..................] - ETA: 2s109912064/258076736 [===========>..................] - ETA: 2s114106368/258076736 [============>.................] - ETA: 2s118300672/258076736 [============>.................] - ETA: 1s122494976/258076736 [=============>................] - ETA: 1s126623744/258076736 [=============>................] - ETA: 1s130883584/258076736 [==============>...............] - ETA: 1s134176768/258076736 [==============>...............] - ETA: 1s137895936/258076736 [===============>..............] - ETA: 1s142090240/258076736 [===============>..............] - ETA: 1s146268160/258076736 [================>.............] - ETA: 1s150462464/258076736 [================>.............] - ETA: 1s154656768/258076736 [================>.............] - ETA: 1s158851072/258076736 [=================>............] - ETA: 1s163061760/258076736 [=================>............] - ETA: 1s167239680/258076736 [==================>...........] - ETA: 1s171450368/258076736 [==================>...........] - ETA: 1s175628288/258076736 [===================>..........] - ETA: 1s179838976/258076736 [===================>..........] - ETA: 1s184016896/258076736 [====================>.........] - ETA: 1s188211200/258076736 [====================>.........] - ETA: 0s192413696/258076736 [=====================>........] - ETA: 0s196599808/258076736 [=====================>........] - ETA: 0s200777728/258076736 [======================>.......] - ETA: 0s204972032/258076736 [======================>.......] - ETA: 0s209166336/258076736 [=======================>......] - ETA: 0s213344256/258076736 [=======================>......] - ETA: 0s217571328/258076736 [========================>.....] - ETA: 0s221716480/258076736 [========================>.....] - ETA: 0s224550912/258076736 [=========================>....] - ETA: 0s228810752/258076736 [=========================>....] - ETA: 0s232038400/258076736 [=========================>....] - ETA: 0s236216320/258076736 [==========================>...] - ETA: 0s240377856/258076736 [==========================>...] - ETA: 0s244555776/258076736 [===========================>..] - ETA: 0s248766464/258076736 [===========================>..] - ETA: 0s252960768/258076736 [============================>.] - ETA: 0s257138688/258076736 [============================>.] - ETA: 0s258080768/258076736 [==============================] - 3s 0us/step
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 128, 128, 3)]     0         
_________________________________________________________________
efficientnetb7 (Functional)  (None, 4, 4, 2560)        64097687  
_________________________________________________________________
flatten (Flatten)            (None, 40960)             0         
_________________________________________________________________
dense (Dense)                (None, 2)                 81922     
=================================================================
Total params: 64,179,609
Trainable params: 81,922
Non-trainable params: 64,097,687
_________________________________________________________________
None
Model summary has been saved to file: /home/mdabdullahal.alamin/alamin/face_mask/model_output/real/batch_jobs/EfficientNet_transfer_learning/model_summary.txt
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 128, 128, 3)]     0         
_________________________________________________________________
efficientnetb7 (Functional)  (None, 4, 4, 2560)        64097687  
_________________________________________________________________
flatten (Flatten)            (None, 40960)             0         
_________________________________________________________________
dense (Dense)                (None, 2)                 81922     
=================================================================
Total params: 64,179,609
Trainable params: 81,922
Non-trainable params: 64,097,687
_________________________________________________________________
2021-11-26 13:56:29.866359: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2021-11-26 13:56:29.904563: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
=========================> Epoch is finished and validation accuracy is: 0.98
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
=========================> Epoch is finished and validation accuracy is: 0.99
Trining over
        loss  accuracy  val_loss  val_accuracy       lr
0   0.095291  0.968437  0.053773      0.981988  0.00010
1   0.037515  0.988299  0.034538      0.991354  0.00010
2   0.030704  0.990954  0.039039      0.986311  0.00010
3   0.027261  0.991839  0.034346      0.990634  0.00010
4   0.024347  0.993215  0.030846      0.989914  0.00010
5   0.022618  0.993904  0.029265      0.990634  0.00010
6   0.019816  0.993904  0.032006      0.989914  0.00010
7   0.017445  0.994690  0.021167      0.992075  0.00010
8   0.017804  0.994494  0.021128      0.992795  0.00010
9   0.014763  0.996067  0.025247      0.989193  0.00010
10  0.014729  0.995969  0.017997      0.994957  0.00005
11  0.014382  0.996657  0.021799      0.992075  0.00005
12  0.016203  0.994494  0.017789      0.992075  0.00005
13  0.013193  0.995674  0.021044      0.993516  0.00005
14  0.014741  0.994887  0.018107      0.992075  0.00005
15  0.011513  0.997050  0.022387      0.992795  0.00005
 1/11 [=>............................] - ETA: 1:11 - loss: 0.0016 - accuracy: 1.0000 2/11 [====>.........................] - ETA: 10s - loss: 9.6184e-04 - accuracy: 1.0000 3/11 [=======>......................] - ETA: 8s - loss: 0.0014 - accuracy: 1.0000      4/11 [=========>....................] - ETA: 7s - loss: 0.0018 - accuracy: 1.0000 5/11 [============>.................] - ETA: 5s - loss: 0.0033 - accuracy: 0.9984 6/11 [===============>..............] - ETA: 4s - loss: 0.0049 - accuracy: 0.9987 7/11 [==================>...........] - ETA: 3s - loss: 0.0124 - accuracy: 0.9967 8/11 [====================>.........] - ETA: 2s - loss: 0.0154 - accuracy: 0.9961 9/11 [=======================>......] - ETA: 1s - loss: 0.0161 - accuracy: 0.995710/11 [==========================>...] - ETA: 0s - loss: 0.0177 - accuracy: 0.995311/11 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.995311/11 [==============================] - 29s 2s/step - loss: 0.0177 - accuracy: 0.9953
Loss: 0.018 Accuracy: 99.533%
6
Model Test dataset:
Accuracy: 99.533%
Loss: 0.018
Total training time 2103 seconds 0.6 Hours

Training epoch stats:         loss  accuracy  val_loss  val_accuracy       lr
0   0.095291  0.968437  0.053773      0.981988  0.00010
1   0.037515  0.988299  0.034538      0.991354  0.00010
2   0.030704  0.990954  0.039039      0.986311  0.00010
3   0.027261  0.991839  0.034346      0.990634  0.00010
4   0.024347  0.993215  0.030846      0.989914  0.00010
5   0.022618  0.993904  0.029265      0.990634  0.00010
6   0.019816  0.993904  0.032006      0.989914  0.00010
7   0.017445  0.994690  0.021167      0.992075  0.00010
8   0.017804  0.994494  0.021128      0.992795  0.00010
9   0.014763  0.996067  0.025247      0.989193  0.00010
10  0.014729  0.995969  0.017997      0.994957  0.00005
11  0.014382  0.996657  0.021799      0.992075  0.00005
12  0.016203  0.994494  0.017789      0.992075  0.00005
13  0.013193  0.995674  0.021044      0.993516  0.00005
14  0.014741  0.994887  0.018107      0.992075  0.00005
15  0.011513  0.997050  0.022387      0.992795  0.00005

Incorrectly Predicted Samples:
mask/898.jpg
without_mask/175.jpg
without_mask/217.jpg
without_mask/378.jpg
without_mask/560.jpg
without_mask/89.jpg

Job ended
Fri Nov 26 14:32:04 MST 2021
